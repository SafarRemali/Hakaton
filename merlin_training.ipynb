{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a93d104-666b-4036-b400-0906b6823483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f86e53-cd92-4ab2-a1f3-5c2a74884d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import perceval as pcvl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from merlin import LexGrouping, QuantumLayer, MeasurementStrategy, ComputationSpace\n",
    "from merlin.builder import CircuitBuilder\n",
    "import perceval as pcvl\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6517f4b4-14af-4ee5-b759-4f1c13634a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./train.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534cca7-3aea-4863-a430-cc2448febfc1",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "108dfe92-0b27-4713-8c0f-f3f02837c1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 494\n",
      "Date range: 2050-01-01 → 2051-12-23\n",
      "Number of surface points: 224\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tenor : 1; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 2; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 3; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 4; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 5; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 6; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 7; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 8; Maturity : 0.0833333333333333</th>\n",
       "      <th>Tenor : 9; Maturity : 0.0833333333333333</th>\n",
       "      <th>...</th>\n",
       "      <th>Tenor : 5; Maturity : 30</th>\n",
       "      <th>Tenor : 6; Maturity : 30</th>\n",
       "      <th>Tenor : 7; Maturity : 30</th>\n",
       "      <th>Tenor : 8; Maturity : 30</th>\n",
       "      <th>Tenor : 9; Maturity : 30</th>\n",
       "      <th>Tenor : 10; Maturity : 30</th>\n",
       "      <th>Tenor : 15; Maturity : 30</th>\n",
       "      <th>Tenor : 20; Maturity : 30</th>\n",
       "      <th>Tenor : 25; Maturity : 30</th>\n",
       "      <th>Tenor : 30; Maturity : 30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2050-01-01</td>\n",
       "      <td>0.028565</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.040127</td>\n",
       "      <td>0.040762</td>\n",
       "      <td>0.040466</td>\n",
       "      <td>0.038953</td>\n",
       "      <td>0.037553</td>\n",
       "      <td>0.036768</td>\n",
       "      <td>0.036646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331053</td>\n",
       "      <td>0.329056</td>\n",
       "      <td>0.330997</td>\n",
       "      <td>0.324676</td>\n",
       "      <td>0.325758</td>\n",
       "      <td>0.322393</td>\n",
       "      <td>0.345859</td>\n",
       "      <td>0.359162</td>\n",
       "      <td>0.346670</td>\n",
       "      <td>0.337670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050-01-02</td>\n",
       "      <td>0.029334</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>0.040982</td>\n",
       "      <td>0.041638</td>\n",
       "      <td>0.041336</td>\n",
       "      <td>0.039815</td>\n",
       "      <td>0.038397</td>\n",
       "      <td>0.037631</td>\n",
       "      <td>0.037504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336319</td>\n",
       "      <td>0.334434</td>\n",
       "      <td>0.336568</td>\n",
       "      <td>0.330244</td>\n",
       "      <td>0.331462</td>\n",
       "      <td>0.328144</td>\n",
       "      <td>0.351816</td>\n",
       "      <td>0.365197</td>\n",
       "      <td>0.350993</td>\n",
       "      <td>0.340822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2050-01-03</td>\n",
       "      <td>0.028696</td>\n",
       "      <td>0.038816</td>\n",
       "      <td>0.040328</td>\n",
       "      <td>0.041042</td>\n",
       "      <td>0.040804</td>\n",
       "      <td>0.039329</td>\n",
       "      <td>0.037968</td>\n",
       "      <td>0.037216</td>\n",
       "      <td>0.037107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333634</td>\n",
       "      <td>0.331707</td>\n",
       "      <td>0.333800</td>\n",
       "      <td>0.327487</td>\n",
       "      <td>0.328710</td>\n",
       "      <td>0.325436</td>\n",
       "      <td>0.348915</td>\n",
       "      <td>0.362236</td>\n",
       "      <td>0.348652</td>\n",
       "      <td>0.339027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2050-01-05</td>\n",
       "      <td>0.030854</td>\n",
       "      <td>0.041536</td>\n",
       "      <td>0.043035</td>\n",
       "      <td>0.043605</td>\n",
       "      <td>0.043241</td>\n",
       "      <td>0.041556</td>\n",
       "      <td>0.039977</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.038968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.336884</td>\n",
       "      <td>0.335106</td>\n",
       "      <td>0.337548</td>\n",
       "      <td>0.331279</td>\n",
       "      <td>0.332811</td>\n",
       "      <td>0.329771</td>\n",
       "      <td>0.353246</td>\n",
       "      <td>0.366100</td>\n",
       "      <td>0.351404</td>\n",
       "      <td>0.340465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2050-01-06</td>\n",
       "      <td>0.030406</td>\n",
       "      <td>0.041174</td>\n",
       "      <td>0.042681</td>\n",
       "      <td>0.043266</td>\n",
       "      <td>0.042937</td>\n",
       "      <td>0.041253</td>\n",
       "      <td>0.039685</td>\n",
       "      <td>0.038867</td>\n",
       "      <td>0.038667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333249</td>\n",
       "      <td>0.331426</td>\n",
       "      <td>0.333830</td>\n",
       "      <td>0.327580</td>\n",
       "      <td>0.329123</td>\n",
       "      <td>0.326146</td>\n",
       "      <td>0.349390</td>\n",
       "      <td>0.362048</td>\n",
       "      <td>0.348331</td>\n",
       "      <td>0.338022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Tenor : 1; Maturity : 0.0833333333333333  \\\n",
       "0 2050-01-01                                  0.028565   \n",
       "1 2050-01-02                                  0.029334   \n",
       "2 2050-01-03                                  0.028696   \n",
       "3 2050-01-05                                  0.030854   \n",
       "4 2050-01-06                                  0.030406   \n",
       "\n",
       "   Tenor : 2; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.038700   \n",
       "1                                  0.039499   \n",
       "2                                  0.038816   \n",
       "3                                  0.041536   \n",
       "4                                  0.041174   \n",
       "\n",
       "   Tenor : 3; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.040127   \n",
       "1                                  0.040982   \n",
       "2                                  0.040328   \n",
       "3                                  0.043035   \n",
       "4                                  0.042681   \n",
       "\n",
       "   Tenor : 4; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.040762   \n",
       "1                                  0.041638   \n",
       "2                                  0.041042   \n",
       "3                                  0.043605   \n",
       "4                                  0.043266   \n",
       "\n",
       "   Tenor : 5; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.040466   \n",
       "1                                  0.041336   \n",
       "2                                  0.040804   \n",
       "3                                  0.043241   \n",
       "4                                  0.042937   \n",
       "\n",
       "   Tenor : 6; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.038953   \n",
       "1                                  0.039815   \n",
       "2                                  0.039329   \n",
       "3                                  0.041556   \n",
       "4                                  0.041253   \n",
       "\n",
       "   Tenor : 7; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.037553   \n",
       "1                                  0.038397   \n",
       "2                                  0.037968   \n",
       "3                                  0.039977   \n",
       "4                                  0.039685   \n",
       "\n",
       "   Tenor : 8; Maturity : 0.0833333333333333  \\\n",
       "0                                  0.036768   \n",
       "1                                  0.037631   \n",
       "2                                  0.037216   \n",
       "3                                  0.039167   \n",
       "4                                  0.038867   \n",
       "\n",
       "   Tenor : 9; Maturity : 0.0833333333333333  ...  Tenor : 5; Maturity : 30  \\\n",
       "0                                  0.036646  ...                  0.331053   \n",
       "1                                  0.037504  ...                  0.336319   \n",
       "2                                  0.037107  ...                  0.333634   \n",
       "3                                  0.038968  ...                  0.336884   \n",
       "4                                  0.038667  ...                  0.333249   \n",
       "\n",
       "   Tenor : 6; Maturity : 30  Tenor : 7; Maturity : 30  \\\n",
       "0                  0.329056                  0.330997   \n",
       "1                  0.334434                  0.336568   \n",
       "2                  0.331707                  0.333800   \n",
       "3                  0.335106                  0.337548   \n",
       "4                  0.331426                  0.333830   \n",
       "\n",
       "   Tenor : 8; Maturity : 30  Tenor : 9; Maturity : 30  \\\n",
       "0                  0.324676                  0.325758   \n",
       "1                  0.330244                  0.331462   \n",
       "2                  0.327487                  0.328710   \n",
       "3                  0.331279                  0.332811   \n",
       "4                  0.327580                  0.329123   \n",
       "\n",
       "   Tenor : 10; Maturity : 30  Tenor : 15; Maturity : 30  \\\n",
       "0                   0.322393                   0.345859   \n",
       "1                   0.328144                   0.351816   \n",
       "2                   0.325436                   0.348915   \n",
       "3                   0.329771                   0.353246   \n",
       "4                   0.326146                   0.349390   \n",
       "\n",
       "   Tenor : 20; Maturity : 30  Tenor : 25; Maturity : 30  \\\n",
       "0                   0.359162                   0.346670   \n",
       "1                   0.365197                   0.350993   \n",
       "2                   0.362236                   0.348652   \n",
       "3                   0.366100                   0.351404   \n",
       "4                   0.362048                   0.348331   \n",
       "\n",
       "   Tenor : 30; Maturity : 30  \n",
       "0                   0.337670  \n",
       "1                   0.340822  \n",
       "2                   0.339027  \n",
       "3                   0.340465  \n",
       "4                   0.338022  \n",
       "\n",
       "[5 rows x 225 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data (day-first dates)\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Keep Date as first column\n",
    "df = df[['Date'] + [c for c in df.columns if c != 'Date']]\n",
    "feature_cols = [c for c in df.columns if c != 'Date']\n",
    "\n",
    "print(f\"Rows: {len(df)}\")\n",
    "print(f\"Date range: {df['Date'].min().date()} → {df['Date'].max().date()}\")\n",
    "print(f\"Number of surface points: {len(feature_cols)}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f393b88a-f31a-4da0-850d-06226fa23510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinanceDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"PyTorch Dataset for swaption volatility data.\"\"\"\n",
    "    \n",
    "    def __init__(self, X, history=1, n_pred=1):\n",
    "        self.X = torch.FloatTensor(X.values if isinstance(X, pd.DataFrame) else X)\n",
    "        self.history = history\n",
    "        self.n_pred = n_pred\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.history - self.n_pred\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx:idx+self.history], self.X[idx+self.history+1:idx+self.history+self.n_pred+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df54a19d-7b6c-4f0e-95d8-6b25ae927a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 484 samples\n",
      "Input dim: torch.Size([6, 224]), Target dim: torch.Size([3, 224])\n"
     ]
    }
   ],
   "source": [
    "# Build a simple PyTorch Dataset using the next-day target\n",
    "history=6\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[feature_cols].shift(-1)\n",
    "\n",
    "# drop last row where target is NaN\n",
    "mask = ~y.isnull().any(axis=1)\n",
    "X = X[mask].reset_index(drop=True)\n",
    "\n",
    "dataset = FinanceDataset(X, history=history, n_pred=3)\n",
    "print(f\"Dataset size: {len(dataset)} samples\")\n",
    "print(f\"Input dim: {dataset[0][0].shape}, Target dim: {dataset[0][1].shape}\")\n",
    "\n",
    "input_dim = dataset[0][0].flatten().shape[0]\n",
    "target_dim = dataset[0][1].flatten().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d5bc49-0d26-49c7-a6fe-30f5ea1e2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "trainset, testset = random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=10, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=len(testset), shuffle=False) #no batches for testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea221072-0e66-4c38-b680-37e9b7799fd1",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7600fc89-0161-4252-8ed2-3f122e2ee198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, device=\"cpu\", silent=True):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs, targets = next(iter(loader))\n",
    "        \n",
    "        inputs = inputs.to(device).flatten(start_dim=1)\n",
    "        targets = targets.to(device).flatten(start_dim=1)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # --- R^2 Calculation ---\n",
    "        # SS_res: Residual Sum of Squares (Variance of the error)\n",
    "        sum_residual = ((targets - outputs)**2).sum(dim=0)\n",
    "        \n",
    "        # SS_tot: Total Sum of Squares (Variance of the data)\n",
    "        target_mean = targets.mean(dim=0, keepdim=True)\n",
    "        sum_square = ((targets - target_mean)**2).sum(dim=0)\n",
    "        \n",
    "        r_squared = 1 - sum_residual / (sum_square + 1e-8)\n",
    "        \n",
    "        mse = torch.nn.functional.mse_loss(outputs, targets, reduction='mean').item()\n",
    "        root_mse = mse**0.5\n",
    "        \n",
    "        mae = torch.nn.functional.l1_loss(outputs, targets, reduction='mean').item()\n",
    "        \n",
    "    if not silent:\n",
    "        print(f\"Test Results:\")\n",
    "        print(f\"\\tMSE: {mse:.4f}\")\n",
    "        print(f\"\\tRoot MSE: {root_mse:.4f}\")\n",
    "        print(f\"\\tMAE: {mae:.4f}\")\n",
    "        print(f\"\\tR^2: {r_squared.mean().item():.4f}\")\n",
    "    \n",
    "    return mse, root_mse, mae, r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d80bb32a-5450-45cf-9d74-39ede2968a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example(model, loader):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        inputs, targets = next(iter(loader))\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        relative_error = torch.abs(outputs - targets) / (torch.abs(targets) + 1e-7)\n",
    "            \n",
    "        print(f'Target={targets}, Output={outputs}, Rel_error={relative_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344cc16-0382-4f23-86ba-735fa59d085e",
   "metadata": {},
   "source": [
    "# Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfb314ae-2190-4f49-a198-cc944af02538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optim, n_epochs=10, device='cpu'):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    l = []\n",
    "\n",
    "    pbar = tqdm(range(n_epochs))\n",
    "    \n",
    "    for i in pbar:\n",
    "        cur_loss = 0\n",
    "        cur_samples = 0\n",
    "        \n",
    "        for input, target in trainloader:\n",
    "            input = input.to(device)\n",
    "            target = target.flatten(start_dim=1).to(device)\n",
    "            \n",
    "            output = model(input)\n",
    "    \n",
    "            optim.zero_grad()\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            cur_loss += loss.sum().cpu().item()\n",
    "            cur_samples += input.shape[0]\n",
    "            pbar.set_postfix(loss=cur_loss / cur_samples)\n",
    "    \n",
    "        #cur_loss /= len(trainloader)\n",
    "        #pbar.set_postfix(prev_loss = cur_loss / cur_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b75d003-df7b-4405-bff6-28157c646d7f",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c48032bc-fe76-499e-9383-a0675ead2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classical MLP\n",
    "def classical_model(h_dim=1000):\n",
    "    \"\"\"\n",
    "    Return a model and its actual number of\n",
    "    parameters (proportional to `h_dim`)\n",
    "    \"\"\"\n",
    "    model = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(input_dim, h_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(h_dim, target_dim)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "#print(f'Classical MLP size={sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4da2be2c-8c6d-4a3d-93e6-b011f8383504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hybrid quantum model impl. with MerLin\n",
    "def create_block(modes, step, max_param, univ_len):\n",
    "    cir = pcvl.Circuit(modes)\n",
    "\n",
    "    for i in range(modes):\n",
    "        if i+step*modes >= max_param:\n",
    "            break\n",
    "\n",
    "        cir.add(i, pcvl.PS(pcvl.P(f'input{i+step*modes}')))\n",
    "\n",
    "    rl = pcvl.GenericInterferometer(\n",
    "        modes,\n",
    "        lambda i: pcvl.BS()\n",
    "        // pcvl.PS(pcvl.P(f\"theta_ri{i+univ_len*step}\"))\n",
    "        // pcvl.BS()\n",
    "        // pcvl.PS(pcvl.P(f\"theta_ro{i+univ_len*step}\")),\n",
    "        shape=pcvl.InterferometerShape.RECTANGLE,\n",
    "    )\n",
    "    cir.add(0, rl)\n",
    "\n",
    "    return cir\n",
    "    \n",
    "\n",
    "modes = 10\n",
    "# left generic interferometer\n",
    "wl = pcvl.GenericInterferometer(\n",
    "    modes,\n",
    "    lambda i: pcvl.BS()\n",
    "    // pcvl.PS(pcvl.P(f\"theta_li{i}\"))\n",
    "    // pcvl.BS()\n",
    "    // pcvl.PS(pcvl.P(f\"theta_lo{i}\")),\n",
    "    shape=pcvl.InterferometerShape.RECTANGLE,\n",
    ")\n",
    "\n",
    "circuit = pcvl.Circuit(modes)\n",
    "circuit.add(0,wl)\n",
    "for i in range(0, input_dim, modes):\n",
    "    step = i // modes\n",
    "    circuit.add(0, create_block(modes, step, input_dim, len(wl.params)))\n",
    "\n",
    "quantum_layer = QuantumLayer(\n",
    "    input_size=input_dim,\n",
    "    circuit=circuit,\n",
    "    n_photons=3,\n",
    "    trainable_parameters=[\"theta\"],\n",
    "    input_parameters=[\"input\"],\n",
    "    dtype=dataset.X.dtype,\n",
    ")\n",
    "\n",
    "def quantum_model(h_dim=1000):\n",
    "    model = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        quantum_layer,\n",
    "        LexGrouping(quantum_layer.output_size, 3*h_dim),\n",
    "        nn.Linear(3*h_dim, target_dim)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "#print(f'Hybrid quantum model size={sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
    "#pcvl.pdisplay(circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2608e-f97f-43dd-b207-fcdcb86f3b25",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17b3ada6-4835-4c35-95d9-9f30d26cb0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model=Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): QuantumLayer(\n",
      "    (_photon_loss_transform): PhotonLossTransform()\n",
      "    (_detector_transform): DetectorTransform()\n",
      "    (measurement_mapping): Probabilities()\n",
      "  )\n",
      "  (2): LexGrouping()\n",
      "  (3): Linear(in_features=300, out_features=672, bias=True)\n",
      ")\n",
      "Model size=214512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:43<?, ?it/s, loss=0.00583]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;241m.\u001b[39mrequires_grad)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, optim, n_epochs, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, target)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m cur_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[0;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = quantum_model(h_dim=100)\n",
    "lr = 1e-3\n",
    "loss_fn = nn.MSELoss()\n",
    "optim = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(f'Model={model}')\n",
    "print(f'Model size={sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
    "\n",
    "train(model, loss_fn, optim, device=device, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f13ebf47-2187-4ba8-9365-e4423af7a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights/classical_model_hist6.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8f67e62-6c71-44f0-b6fd-c26aee609dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target=tensor([[0.0353, 0.0448, 0.0466,  ..., 0.4189, 0.3894, 0.3700],\n",
      "        [0.0396, 0.0469, 0.0486,  ..., 0.4620, 0.4245, 0.3992],\n",
      "        [0.0238, 0.0334, 0.0362,  ..., 0.3610, 0.3406, 0.3296],\n",
      "        ...,\n",
      "        [0.0339, 0.0446, 0.0474,  ..., 0.4194, 0.3853, 0.3642],\n",
      "        [0.0232, 0.0330, 0.0361,  ..., 0.3522, 0.3328, 0.3224],\n",
      "        [0.0254, 0.0368, 0.0402,  ..., 0.3531, 0.3330, 0.3212]]), Output=tensor([[0.0332, 0.0410, 0.0448,  ..., 0.4041, 0.3807, 0.3640],\n",
      "        [0.0388, 0.0432, 0.0472,  ..., 0.4597, 0.4230, 0.4001],\n",
      "        [0.0221, 0.0321, 0.0367,  ..., 0.3488, 0.3329, 0.3238],\n",
      "        ...,\n",
      "        [0.0317, 0.0422, 0.0449,  ..., 0.4163, 0.3856, 0.3679],\n",
      "        [0.0233, 0.0331, 0.0378,  ..., 0.3408, 0.3222, 0.3139],\n",
      "        [0.0244, 0.0358, 0.0406,  ..., 0.3443, 0.3239, 0.3140]]), Rel_error=tensor([[0.0609, 0.0829, 0.0383,  ..., 0.0354, 0.0224, 0.0162],\n",
      "        [0.0183, 0.0778, 0.0292,  ..., 0.0049, 0.0036, 0.0023],\n",
      "        [0.0725, 0.0374, 0.0136,  ..., 0.0337, 0.0228, 0.0174],\n",
      "        ...,\n",
      "        [0.0646, 0.0546, 0.0520,  ..., 0.0073, 0.0007, 0.0100],\n",
      "        [0.0066, 0.0027, 0.0475,  ..., 0.0322, 0.0317, 0.0265],\n",
      "        [0.0385, 0.0271, 0.0098,  ..., 0.0247, 0.0272, 0.0226]])\n"
     ]
    }
   ],
   "source": [
    "example(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6259c6e8-1008-4370-a932-d452add43e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "\tMSE: 0.0001\n",
      "\tRoot MSE: 0.0107\n",
      "\tMAE: 0.0082\n",
      "\tR^2: 0.6909\n"
     ]
    }
   ],
   "source": [
    "_ = test(model, testloader, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e85ca7-294e-428e-8f35-6f0273e381c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
